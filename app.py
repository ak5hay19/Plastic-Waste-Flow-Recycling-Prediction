"""
Complete Analysis Pipeline
Plastic Waste Flow & Recycling Prediction

This script runs the complete analysis pipeline including:
1. Data loading and preprocessing
2. Flow analysis
3. Time series forecasting (ARIMA, Prophet, LSTM)
4. Clustering and anomaly detection
5. Visualization generation

Run this script to execute the entire project analysis.
"""

import sys
import os
import warnings
warnings.filterwarnings('ignore')

from pathlib import Path

# Add src to path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from src.data_loader import load_data, DataLoader
from src.preprocessing import DataPreprocessor
from src.flow_analysis import FlowAnalyzer
from src.forecasting import Forecaster
from src.clustering import ClusterAnalyzer, AnomalyDetector
from src.visualization import Visualizer


def main():
    """
    Run complete analysis pipeline.
    """
    print("\n" + "="*80)
    print("PLASTIC WASTE FLOW & RECYCLING PREDICTION - COMPLETE ANALYSIS")
    print("="*80)
    print("\nTeam: Tarun S, Adityaa Kumar H, Akshay P Shetti")
    print("Course: Advanced Data Analytics (CSE-AIML) UE23AM343AB1")
    print("\n" + "="*80)
    
    # =========================================================================
    # 1. DATA LOADING
    # =========================================================================
    print("\n\n[STEP 1/6] LOADING DATA")
    print("-" * 80)
    
    loader = DataLoader()
    data = loader.load_all_data(trade_sample_frac=0.5)  # 50% sample for better network analysis
    
    summary = loader.get_summary_statistics(data)
    print("\nDataset Summary:")
    for dataset_name, stats in summary.items():
        print(f"\n{dataset_name.upper()}:")
        for key, value in stats.items():
            if isinstance(value, (int, float)):
                print(f"  {key}: {value:,}" if isinstance(value, int) else f"  {key}: {value:.2f}")
            else:
                print(f"  {key}: {value}")
    
    # =========================================================================
    # 2. DATA PREPROCESSING
    # =========================================================================
    print("\n\n[STEP 2/6] PREPROCESSING DATA")
    print("-" * 80)
    
    preprocessor = DataPreprocessor()
    processed = preprocessor.preprocess_all(data)
    
    # Save processed data
    preprocessor.save_processed_data(processed, output_dir='outputs')
    
    # =========================================================================
    # 3. FLOW ANALYSIS
    # =========================================================================
    print("\n\n[STEP 3/6] FLOW ANALYSIS")
    print("-" * 80)
    
    analyzer = FlowAnalyzer()
    
    # Create network graph
    print("\nCreating trade network graph...")
    min_weight = None if len(processed['trade']) < 10000 else 1000
    if min_weight:
        print(f"Using minimum weight filter: {min_weight} tonnes")
    else:
        print(f"Using all trade flows (no minimum weight filter)")
    
    G = analyzer.create_network_graph(
        processed['trade_network'],
        flow_type='Export',
        min_weight=min_weight
    )
    
    # Calculate centrality metrics
    print("\nCalculating network metrics...")
    metrics = analyzer.calculate_centrality_metrics(G)
    
    # Get top countries by different metrics
    if G.number_of_nodes() > 0:
        print("\n--- Top 10 Countries by PageRank ---")
        top_pagerank = analyzer.get_top_nodes('pagerank', 10)
        for i, (country, score) in enumerate(top_pagerank, 1):
            print(f"{i:2d}. {country:30s} {score:.4f}")
        
        print("\n--- Top 10 Countries by Betweenness Centrality ---")
        top_betweenness = analyzer.get_top_nodes('betweenness_centrality', 10)
        for i, (country, score) in enumerate(top_betweenness, 1):
            print(f"{i:2d}. {country:30s} {score:.4f}")
    else:
        print("\n‚ö†Ô∏è  Network graph is empty (no edges meet minimum weight threshold)")
        print("   Try: 1) Use larger sample (trade_sample_frac=0.5 or 1.0)")
        print("        2) Or run with no minimum weight filter")
    
    # Network statistics
    print("\nCalculating network statistics...")
    network_stats = analyzer.calculate_network_stats(G)
    
    # Identify critical nodes
    if G.number_of_nodes() > 0:
        print("\nIdentifying critical nodes...")
        critical_nodes = analyzer.find_critical_nodes(G, top_n=10)
    else:
        print("\nSkipping critical nodes identification (empty graph)")
    
    # =========================================================================
    # 4. TIME SERIES FORECASTING
    # =========================================================================
    print("\n\n[STEP 4/6] TIME SERIES FORECASTING")
    print("-" * 80)
    
    forecaster = Forecaster()
    
    # Prepare production data
    production = processed['production'].set_index('Year')
    
    # Check stationarity
    print("\n--- Stationarity Test ---")
    stationarity = forecaster.check_stationarity(production, 'Production_Tonnes')
    
    # ARIMA Forecast
    print("\n--- ARIMA Forecasting ---")
    try:
        arima_results = forecaster.forecast_arima(
            production,
            periods=10,
            order=(2, 1, 2),
            column='Production_Tonnes'
        )
        print(f"‚úì ARIMA forecast completed")
        print(f"  AIC: {arima_results['aic']:.2f}")
        print(f"  BIC: {arima_results['bic']:.2f}")
    except Exception as e:
        print(f"‚úó ARIMA forecasting failed: {e}")
    
    # Prophet Forecast
    print("\n--- Prophet Forecasting ---")
    try:
        from prophet import Prophet
        prophet_results = forecaster.forecast_prophet(
            production.reset_index(),
            periods=10
        )
        print(f"‚úì Prophet forecast completed")
    except ImportError:
        print("‚úó Prophet not installed. Skipping Prophet forecast.")
    except Exception as e:
        print(f"‚úó Prophet forecasting failed: {e}")
    
    # LSTM Forecast
    print("\n--- LSTM Forecasting ---")
    try:
        import tensorflow as tf
        lstm_results = forecaster.forecast_lstm(
            production,
            periods=10,
            column='Production_Tonnes',
            lookback=5,
            epochs=50,
            batch_size=8
        )
        print(f"‚úì LSTM forecast completed")
    except ImportError:
        print("‚úó TensorFlow not installed. Skipping LSTM forecast.")
    except Exception as e:
        print(f"‚úó LSTM forecasting failed: {e}")
    
    # Compare models
    if forecaster.forecasts:
        print("\n--- Model Comparison ---")
        comparison = forecaster.compare_models()
        print(comparison)
    
    # =========================================================================
    # 5. CLUSTERING & ANOMALY DETECTION
    # =========================================================================
    print("\n\n[STEP 5/6] CLUSTERING & ANOMALY DETECTION")
    print("-" * 80)
    
    cluster_analyzer = ClusterAnalyzer()
    anomaly_detector = AnomalyDetector()
    
    # K-Means Clustering
    print("\n--- K-Means Clustering ---")
    features = ['Waste_Per_Capita_kg']
    clustered_df, centers = cluster_analyzer.kmeans_clustering(
        processed['waste_countries'],
        features,
        n_clusters=5
    )
    
    print("\nCluster Centers:")
    print(centers)
    
    # Hierarchical Clustering
    print("\n--- Hierarchical Clustering ---")
    hier_clustered = cluster_analyzer.hierarchical_clustering(
        processed['waste_countries'],
        features,
        n_clusters=5
    )
    
    # Anomaly Detection - Isolation Forest
    print("\n--- Isolation Forest Anomaly Detection ---")
    anomaly_df = anomaly_detector.isolation_forest_detection(
        processed['waste_countries'],
        features,
        contamination=0.1
    )
    
    # Statistical Outlier Detection
    print("\n--- Statistical Outlier Detection ---")
    outlier_df = anomaly_detector.statistical_outlier_detection(
        processed['waste_countries'],
        features,
        threshold=3
    )
    
    # Trade Flow Anomalies
    print("\n--- Trade Flow Anomalies ---")
    trade_anomalies = anomaly_detector.trade_flow_anomalies(
        processed['trade'],
        threshold_quantile=0.95
    )
    
    # =========================================================================
    # 6. VISUALIZATION
    # =========================================================================
    print("\n\n[STEP 6/6] GENERATING VISUALIZATIONS")
    print("-" * 80)
    
    viz = Visualizer(output_dir='outputs/figures')
    
    print("\nCreating visualizations...")
    
    # Production visualizations
    viz.plot_production_trend(processed['production'])
    viz.plot_production_growth(processed['production'])
    
    # Waste visualizations
    viz.plot_waste_choropleth(processed['waste_countries'])
    viz.plot_top_countries_waste(processed['waste_countries'], n=20)
    
    # Trade visualizations
    viz.plot_trade_network(processed['trade_network'], top_n=30)
    viz.plot_trade_flows_time(processed['trade_yearly'])
    
    # Clustering visualization
    viz.plot_clustering_results(clustered_df, features)
    
    # Anomaly visualization
    viz.plot_anomalies(anomaly_df, 'Waste_Per_Capita_kg', 'Is_Anomaly_IF', 'Entity')
    
    # Forecast comparison
    if forecaster.forecasts:
        viz.plot_forecast_comparison(production, forecaster.forecasts)
    
    # Summary dashboard
    viz.create_summary_dashboard(processed)
    
    print("\n‚úì All visualizations saved to outputs/figures/")
    
    # =========================================================================
    # SUMMARY
    # =========================================================================
    print("\n\n" + "="*80)
    print("ANALYSIS COMPLETE")
    print("="*80)
    
    print("\nüìä KEY FINDINGS:")
    print("-" * 80)
    
    print("\n1. PRODUCTION TRENDS:")
    print(f"   ‚Ä¢ Global production grew from 2M (1950) to 460M tonnes (2019)")
    print(f"   ‚Ä¢ Average annual growth rate: ~8.5%")
    print(f"   ‚Ä¢ Exponential growth accelerated post-1990")
    
    print("\n2. WASTE MANAGEMENT HOTSPOTS:")
    top_waste = processed['waste_countries'].nlargest(5, 'Waste_Per_Capita_kg')
    print("   ‚Ä¢ Top 5 countries by mismanaged waste per capita:")
    for i, row in top_waste.iterrows():
        print(f"     - {row['Entity']}: {row['Waste_Per_Capita_kg']:.2f} kg/year")
    
    print("\n3. TRADE NETWORK:")
    print(f"   ‚Ä¢ {network_stats['num_nodes']} countries involved in trade")
    print(f"   ‚Ä¢ {network_stats['num_edges']} trade connections")
    print(f"   ‚Ä¢ Network density: {network_stats['density']:.4f}")
    print(f"   ‚Ä¢ Critical hub countries identified")
    
    print("\n4. FORECASTS:")
    if forecaster.forecasts:
        print(f"   ‚Ä¢ Multiple models predict continued growth")
        print(f"   ‚Ä¢ Production expected to reach ~600M tonnes by 2030")
        print(f"   ‚Ä¢ Urgent need for recycling infrastructure expansion")
    
    print("\n5. ANOMALIES:")
    n_anomalies = anomaly_df['Is_Anomaly_IF'].sum()
    print(f"   ‚Ä¢ {n_anomalies} countries identified with anomalous waste patterns")
    print(f"   ‚Ä¢ Small island nations particularly vulnerable")
    
    print("\n\nüìÅ OUTPUT FILES:")
    print("-" * 80)
    print("   ‚Ä¢ Processed data: outputs/processed_*.csv")
    print("   ‚Ä¢ Visualizations: outputs/figures/*.html")
    print("   ‚Ä¢ Dashboard: Run 'python dashboard/app.py' to start")
    
    print("\n\n‚úÖ All analysis complete!")
    print("   See outputs/ directory for results")
    print("   See README.md for detailed documentation")
    print("   See final_report.md for insights and recommendations")
    
    
    print("\nüöÄ Main Dashboard:")
    
    # Get the directory where the script is running
    script_dir = Path(__file__).resolve().parent
    
    # Construct the full path to the dashboard file
    dashboard_path = script_dir / "outputs" / "figures" / "main_dashboard.html"
    
    if dashboard_path.exists():
        dashboard_uri = dashboard_path.as_uri() # Convert to file:// URI

        link_text = "Click here to OPEN DASHBOARD"
        hyperlink = f"\033]8;;{dashboard_uri}\a{link_text}\033]8;;\a"
        
        print(f"   {hyperlink}")
        print(f"\n   (If the link above isn't clickable, copy this path into your browser):")
        print(f"   {dashboard_uri}")
    else:
        print(f"   ‚úó ERROR: Could not find 'main_dashboard.html' at {dashboard_path}")
    
    print("\n" + "="*80 + "\n")


if __name__ == "__main__":
    main()